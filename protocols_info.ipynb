{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from utils.embeddings_utils import (\n",
    "    cosine_similarity,\n",
    "    get_embedding,\n",
    ")\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "# EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(json_file_path, csv_file_path):\n",
    "    with open(json_file_path, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    with open(csv_file_path, \"w\", newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header row\n",
    "        header = list(data[0].keys()) + [\"text\"]\n",
    "        csv_writer.writerow(header)\n",
    "\n",
    "        # Write the data rows\n",
    "        for item in data:\n",
    "            text = \", \".join(str(value) for value in item.values())\n",
    "            row = list(item.values()) + [text]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "json_to_csv(\"data/protocol.json\", \"processed/embeddings/protocol.csv\")\n",
    "df = pd.read_csv(\"processed/embeddings/protocol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    \"\"\"\n",
    "    Remove newlines from a pandas series for better processing.\n",
    "    \"\"\"\n",
    "    serie = serie.str.replace(\"\\n\", \" \")\n",
    "    serie = serie.str.replace(\"\\\\n\", \" \")\n",
    "    serie = serie.str.replace(\"  \", \" \")\n",
    "    serie = serie.str.replace(\"  \", \" \")\n",
    "    return serie\n",
    "\n",
    "\n",
    "df[\"text\"] = remove_newlines(df[\"text\"])\n",
    "df.to_csv(\"processed/embeddings/protocol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"] = df[\"text\"].apply(\n",
    "    lambda x: get_embedding(text=x, model=EMBEDDING_MODEL)\n",
    ")\n",
    "\n",
    "df.to_csv(\"processed/embeddings/protocol.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find relevant embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(df, query, top_n=3):\n",
    "    query_embedding = get_embedding(text=query, model=EMBEDDING_MODEL)\n",
    "\n",
    "    def calculate_similarity(row):\n",
    "        return (\n",
    "            cosine_similarity(query_embedding, row[\"embedding\"]),\n",
    "            row[\"id\"],\n",
    "            row[\"address\"],\n",
    "        )\n",
    "\n",
    "    protocol_to_score_list = [calculate_similarity(row) for _, row in df.iterrows()]\n",
    "    protocol_to_score_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    top_cases = protocol_to_score_list[:top_n]\n",
    "    return top_cases\n",
    "\n",
    "\n",
    "def print_search_results_pretty(result):\n",
    "    for score, id, address in result:\n",
    "        print(f\"Score: {score.round(4)}\")\n",
    "        print(f\"ID: {id}\")\n",
    "        print(f\"Contract Address: {address}\")\n",
    "        print(\"-\" * 70)  # separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(df, \"usdc, yearn\")\n",
    "print_search_results_pretty(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(df, \"usdt, yearn\")\n",
    "print_search_results_pretty(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(df, \"dai, yearn v3\")\n",
    "print_search_results_pretty(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(df, \"dai, ethereum\")\n",
    "print_search_results_pretty(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suggested': {'score': 0.7062171595431709, 'id': 'yearn_polygon_usdc_vault', 'address': '0xA013Fbd4b711f9ded6fB09C1c0d358E2FbC2EAA0'}, 'other_options': [{'score': 0.623891719812112, 'id': 'yearn_polygon_usdt_vault', 'address': '0x84E13785B5a27879921D6Ff77f8f6687E9d5b2f7'}, {'score': 0.6059552624183242, 'id': 'yearn_polygon_dai_vault', 'address': '0x90b2f54C6aDDAD41b8f6c4fCCd555197BC0F773B'}, {'score': 0.5750262632156996, 'id': 'yearn_polygon_weth_vault', 'address': '0x305F25377d0a39091e99B975558b1bdfC3975654'}]}\n"
     ]
    }
   ],
   "source": [
    "from utils.protocol_searcher import ProtocolSearcher\n",
    "\n",
    "searcher = ProtocolSearcher()\n",
    "result = searcher.search_protocol(\"usdc, yearn\", \"polygon\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
